


http://school.pages.takima.io/devops-resources/

Part 1 - Docker sessions
http://school.pages.takima.io/devops-resources/ch1-discover-docker-tp/
Part 2 - GitHub Action session
http://school.pages.takima.io/devops-resources/ch2-discover-github-actions-tp/
Part 3 - Ansible session
http://school.pages.takima.io/devops-resources/ch3-discover-ansible-tp/

TECHNOLOGIES








installation of Docker Engine on Ubuntu:

'''
#Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

#Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update

sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

sudo docker run hello-world
'''


docker pull adminer

docker network create app-network

sudo docker run -d --name my_postgrey_app --network app-network -p 5432:5432 oscar/tp1
sudo docker run -d --name adminer --network app-network -p 8090:8080 adminer

We add to the Dockerfile
``` 
COPY ./sql-scripts/* /docker-entrypoint-initdb.d
```
then we rebuild and re run the database image.

sudo docker rm -f my_postgrey_app
sudo docker build . -t oscar/tp1
sudo docker run -d --name my_postgrey_app --network app-network -p 5432:5432 oscar/tp1

Volumes are the preferred mechanism for persisting data generated by and used by Docker containers (like databases).
-v /my/own/datadir:/var/lib/postgresql/data

sudo docker run -d --name my_postgrey_app --network app-network --mount type=volume src=volume-tp1,target=/DevOps/tp1:/var/lib/postgresql/data -p 5432:5432 oscar/tp1

sudo docker run -d --name my-postgrey-app --network app-network -v /home/omigeon/devops/tpdocker/database:/var/lib/my-postgrey-app/data -p 5432:5432 my-postgres-db

docker run -d \
  -p "8090:8080" \
  --net=app-network \
  --name=adminer \
  adminer


sudo docker volume inspect volume-tp1
[
    {
        "CreatedAt": "2024-05-28T10:55:07+02:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/volume-tp1/_data",
        "Name": "volume-tp1",
        "Options": null,
        "Scope": "local"
    }
]

To check if the the data is well mounted, we create a teacher table in the database.

Multistage

We have to create the GreetingController class. 
path : /home/omigeon/devops/tpdocker/backend-api/simpleapi/src/main/java/fr/takima/training/simpleapi/Controller

How to integrate multistage ?
Uses a Maven image to compile the Java application.
Copies necessary files (pom.xml, src) and runs the mvn package command to build the JAR file.
Run Stage:
Uses a lighter Amazon Corretto image for running the application, reducing the final image size.
Copies the compiled JAR file from the build stage.
Sets the entry point to run the JAR file with Java.

Hy should we use multistage ?
This approach ensures a clean, minimal runtime environment with only the necessary dependencies to run the application, leading to smaller, more secure, and efficient Docker images.



http


sudo docker build -t frontend_app .
sudo docker run -d --name frontend_app -p 8082:80 --network app-network frontend_app
then localhost:8082 and we see what is written in the index.html

We end up by creating a docker-compose.yml in the src with the three container.
Docker Compose is crucial for modern application development due to its ability to manage multi-container applications efficiently, ensuring consistency, simplifying networking and dependencies, providing easy volume management, supporting multi-environment setups, allowing easy scaling, and offering a simplified command interface. This makes it a powerful tool for both development and production environments.

sudo docker compose up -d
WARN[0000] /home/omigeon/devops/tpdocker/docker-compose.yml: `version` is obsolete 
[+] Running 3/3
 ✔ Container my_postgrey_app  Started                                                                                             3.3s 
 ✔ Container backend-api      Started                                                                                             3.6s 
 ✔ Container frontend_app     Started 



 sudo docker login --username oscarepf --password *********
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded

sudo docker tag tpdocker-frontend oscarepf/tpdocker-frontend:1.0
sudo docker push oscarepf/tpdocker-frontend:1.0

TP Part02

Testcontainers:


Testcontainers is a popular library that provides lightweight, disposable instances of common databases, Selenium web browsers, and other services running in Docker containers. It's widely used for integration testing in Java applications. By using Testcontainers, developers can ensure that their tests run in environments that closely resemble production, improving the reliability and reproducibility of tests

git init
git add *all your docs*
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/oscar92i/takima.git
git push -u origin main


For what purpose do we need to push docker images?
Pushing Docker images is essential for ensuring consistent, portable, scalable, and manageable deployments across different environments. It plays a critical role in modern software development and operations, enabling efficient CI/CD practices, microservices architectures, and cloud-native applications.


Repository secrets


SonarCloud

Project_key: takima-oscar_takima-devops
Organization_key: takima-oscar

      # Build and test with Maven
      - name: Build and test with Maven
        run: mvn -B verify sonar:sonar -Dsonar.projectKey=takima-oscar_takima-devops -Dsonar.organization=takima-oscar -Dsonar.host.url=https://sonarcloud.io -Dsonar.login=${{ secrets.SONAR_TOKEN }}  --file ./backend-api/simple-api-student


ANSIBLE

sudo apt install pipx
pipx install --include-deps ansible
pipx install ansible-core

SSH

A this point we need to connect using ssh protocol.
This can't be done through the EPF VM because it is connected to the EPF WiFi.

So I tried to stop using the EPF VM, but due to the fact that I use an EPF computer, and maybe that I am not an administrator, I couldn't download WSL.

I am not able to end the part 3.